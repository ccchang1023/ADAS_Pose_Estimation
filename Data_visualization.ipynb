{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean broken image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = pd.read_csv(\"./dataset/train.csv\")\n",
    "broken_list = []\n",
    "broken_list.append(df.loc[df['ImageId'] == 'ID_1a5a10365'].index)\n",
    "broken_list.append(df.loc[df['ImageId'] == 'ID_4d238ae90'].index)\n",
    "broken_list.append(df.loc[df['ImageId'] == 'ID_408f58e9f'].index)\n",
    "broken_list.append(df.loc[df['ImageId'] == 'ID_bb1d991f6'].index)\n",
    "broken_list.append(df.loc[df['ImageId'] == 'ID_c44983aeb'].index)\n",
    "\n",
    "for idx in broken_list:\n",
    "    df = df.drop(idx)\n",
    "print(len(df))\n",
    "# df = shuffle(df)\n",
    "df.to_csv(\"./dataset/train_remove.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Mask cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def CreateMaskImages(dir_path,image_Name):\n",
    "    train_image = cv2.imread(\"{}_images/{}.jpg\".format(dir_path,image_Name))\n",
    "    if not os.path.isfile(\"{}_masks/{}.jpg\".format(dir_path,image_Name)):\n",
    "        return train_image\n",
    "    image_mask = cv2.imread(\"{}_masks/{}.jpg\".format(dir_path,image_Name),0)\n",
    "    image_mask = image_mask//200*255\n",
    "#     image_mask = np.ceil((image_mask//255))*255\n",
    "#     image_mask = np.array(image_mask,dtype=np.uint8)\n",
    "\n",
    "#     print(np.max(image_mask),np.min(image_mask))\n",
    "\n",
    "    image_mask_inv = cv2.bitwise_not(image_mask)\n",
    "    res = cv2.bitwise_and(train_image,train_image,mask = image_mask_inv)\n",
    "    #cut upper half,because it doesn't contain cars.\n",
    "#     res = res[res.shape[0] // 2:]\n",
    "    return res\n",
    "    \n",
    "train_pd = pd.read_csv(\"./dataset/train_remove.csv\")\n",
    "train_dir = \"./dataset/train\"\n",
    "data_len = len(train_pd)\n",
    "\n",
    "for idx in range(0,data_len):\n",
    "    if idx%500==0:\n",
    "        print(\"idx:\",idx)\n",
    "    file_name = train_pd['ImageId'].iloc[idx]\n",
    "    res = CreateMaskImages(train_dir,file_name)\n",
    "    cv2.imwrite(\"./dataset/masked_train/\" + file_name + \".jpg\", res)\n",
    "\n",
    "    \n",
    "test_pd = pd.read_csv(\"./dataset/sample_submission.csv\")\n",
    "test_dir = \"./dataset/test\"\n",
    "data_len = len(test_pd)\n",
    "\n",
    "for idx in range(0,data_len):\n",
    "    if idx%500==0:\n",
    "        print(\"idx:\",idx)\n",
    "    file_name = test_pd['ImageId'].iloc[idx]\n",
    "    res = CreateMaskImages(test_dir,file_name)\n",
    "    cv2.imwrite(\"./dataset/masked_test/\" + file_name + \".jpg\", res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# IMG_WIDTH = 1024\n",
    "# IMG_HEIGHT = 320  #IMG_HEIGHT = IMG_WIDTH // 16 * 5\n",
    "\n",
    "# IMG_WIDTH = 1536\n",
    "# IMG_HEIGHT = 512\n",
    "# MODEL_SCALE = 8\n",
    "\n",
    "# IMG_WIDTH = 2048\n",
    "# IMG_HEIGHT = IMG_WIDTH // 4\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "MODEL_SCALE = 8\n",
    "\n",
    "def imread(path, fast_mode=False):\n",
    "    img = cv2.imread(path)\n",
    "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
    "        img = np.array(img[:, :, ::-1])\n",
    "    return img\n",
    "\n",
    "def rotate(x, angle): \n",
    "    x = x + angle \n",
    "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi \n",
    "    return x\n",
    "\n",
    "def _regr_preprocess(regr_dict, flip=False):\n",
    "    if flip:\n",
    "        for k in ['x', 'pitch', 'roll']:\n",
    "            regr_dict[k] = -regr_dict[k]\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] / 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], np.pi)\n",
    "    regr_dict['pitch_sin'] = sin(regr_dict['pitch'])\n",
    "    regr_dict['pitch_cos'] = cos(regr_dict['pitch'])\n",
    "    regr_dict.pop('pitch')\n",
    "    regr_dict.pop('id')\n",
    "    return regr_dict\n",
    "\n",
    "def _regr_back(regr_dict):\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] * 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], -np.pi)\n",
    "    \n",
    "    pitch_sin = regr_dict['pitch_sin'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    pitch_cos = regr_dict['pitch_cos'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    regr_dict['pitch'] = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
    "    return regr_dict\n",
    "\n",
    "def preprocess_image(img, flip=False):\n",
    "    img = img[img.shape[0] // 2:]\n",
    "#     bg = np.ones_like(img) * img.mean(1, keepdims=True).astype(img.dtype)\n",
    "#     bg = bg[:, :img.shape[1] // 6]\n",
    "#     img = np.concatenate([bg, img, bg], 1)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    if flip:\n",
    "        img = img[:,::-1]\n",
    "    return (img / 255).astype('float32')\n",
    "\n",
    "def get_mask_and_regr(img, labels, flip=False):\n",
    "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "    regr_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n",
    "    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
    "    coords = str2coords(labels)\n",
    "    xs, ys = get_img_coords(labels)\n",
    "    for x, y, regr_dict in zip(xs, ys, coords):\n",
    "        x, y = y, x\n",
    "        x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "#         y = (y + img.shape[1] // 6) * IMG_WIDTH / (img.shape[1] * 4/3) / MODEL_SCALE\n",
    "        y = (y) * IMG_WIDTH / (img.shape[1]) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        if x >= 0 and x < IMG_HEIGHT // MODEL_SCALE and y >= 0 and y < IMG_WIDTH // MODEL_SCALE:\n",
    "            mask[x, y] = 1\n",
    "            regr_dict = _regr_preprocess(regr_dict, flip)\n",
    "            regr[x, y] = [regr_dict[n] for n in sorted(regr_dict)]\n",
    "    if flip:\n",
    "        mask = np.array(mask[:,::-1])\n",
    "        regr = np.array(regr[:,::-1])\n",
    "    return mask, regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from math import sqrt, acos, pi, sin, cos\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def expand_df(df, PredictionStringCols):\n",
    "    df = df.dropna().copy()\n",
    "    df['NumCars'] = [int((x.count(' ')+1)/7) for x in df['PredictionString']]\n",
    "    image_id_expanded = [item for item, count in zip(df['ImageId'], df['NumCars']) for i in range(count)]\n",
    "    prediction_strings_expanded = df['PredictionString'].str.split(' ',expand = True).values.reshape(-1,7).astype(float)\n",
    "    prediction_strings_expanded = prediction_strings_expanded[~np.isnan(prediction_strings_expanded).all(axis=1)]\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'ImageId': image_id_expanded,\n",
    "            PredictionStringCols[0]:prediction_strings_expanded[:,0],\n",
    "            PredictionStringCols[1]:prediction_strings_expanded[:,1],\n",
    "            PredictionStringCols[2]:prediction_strings_expanded[:,2],\n",
    "            PredictionStringCols[3]:prediction_strings_expanded[:,3],\n",
    "            PredictionStringCols[4]:prediction_strings_expanded[:,4],\n",
    "            PredictionStringCols[5]:prediction_strings_expanded[:,5],\n",
    "            PredictionStringCols[6]:prediction_strings_expanded[:,6]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def str2coords(s, names):\n",
    "    coords = []\n",
    "    for l in np.array(s.split()).reshape([-1, 7]):\n",
    "        coords.append(dict(zip(names, l.astype('float'))))\n",
    "    return coords\n",
    "\n",
    "def TranslationDistance(p,g, abs_dist = False):\n",
    "    dx = p['x'] - g['x']\n",
    "    dy = p['y'] - g['y']\n",
    "    dz = p['z'] - g['z']\n",
    "    diff0 = (g['x']**2 + g['y']**2 + g['z']**2)**0.5\n",
    "    diff1 = (dx**2 + dy**2 + dz**2)**0.5\n",
    "    if abs_dist:\n",
    "        diff = diff1\n",
    "    else:\n",
    "        diff = diff1/diff0\n",
    "    return diff\n",
    "\n",
    "def RotationDistance(p, g):\n",
    "    true=[ g['pitch'] ,g['yaw'] ,g['roll'] ]\n",
    "    pred=[ p['pitch'] ,p['yaw'] ,p['roll'] ]\n",
    "    q1 = R.from_euler('xyz', true)\n",
    "    q2 = R.from_euler('xyz', pred)\n",
    "    diff = R.inv(q2) * q1\n",
    "    W = np.clip(diff.as_quat()[-1], -1., 1.)\n",
    "    \n",
    "    # in the official metrics code:\n",
    "    # https://www.kaggle.com/c/pku-autonomous-driving/overview/evaluation\n",
    "    #   return Object3D.RadianToDegree( Math.Acos(diff.W) )\n",
    "    # this code treat θ and θ+2π differntly.\n",
    "    # So this should be fixed as follows.\n",
    "    W = (acos(W)*360)/pi\n",
    "    if W > 180:\n",
    "        W = 360 - W\n",
    "    return W\n",
    "\n",
    "def print_pr_curve(result_flg, scores, recall_total=1):\n",
    "    average_precision = average_precision_score(result_flg, scores)\n",
    "    precision, recall, _ = precision_recall_curve(result_flg, scores)\n",
    "    recall *= recall_total\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.show()\n",
    "    \n",
    "thres_tr_list = [0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "thres_ro_list = [50, 45, 40, 35, 30, 25, 20, 15, 10, 5]\n",
    "\n",
    "def check_match(idx,train_df,valid_df):\n",
    "    keep_gt=False\n",
    "    thre_tr_dist = thres_tr_list[idx]\n",
    "    thre_ro_dist = thres_ro_list[idx]\n",
    "    train_dict = {imgID:str2coords(s, names=['carid_or_score', 'pitch', 'yaw', 'roll', 'x', 'y', 'z']) for imgID,s in zip(train_df['ImageId'],train_df['PredictionString'])}\n",
    "    valid_dict = {imgID:str2coords(s, names=['pitch', 'yaw', 'roll', 'x', 'y', 'z', 'carid_or_score']) for imgID,s in zip(valid_df['ImageId'],valid_df['PredictionString'])}\n",
    "    result_flg = [] # 1 for TP, 0 for FP\n",
    "    scores = []\n",
    "    MAX_VAL = 10**10\n",
    "    for img_id in valid_dict:\n",
    "        for pcar in sorted(valid_dict[img_id], key=lambda x: -x['carid_or_score']):\n",
    "            # find nearest GT\n",
    "            min_tr_dist = MAX_VAL\n",
    "            min_idx = -1\n",
    "            for idx, gcar in enumerate(train_dict[img_id]):\n",
    "                tr_dist = TranslationDistance(pcar,gcar)\n",
    "                if tr_dist < min_tr_dist:\n",
    "                    min_tr_dist = tr_dist\n",
    "                    min_ro_dist = RotationDistance(pcar,gcar)\n",
    "                    min_idx = idx\n",
    "                    \n",
    "            # set the result\n",
    "            if min_tr_dist < thre_tr_dist and min_ro_dist < thre_ro_dist:\n",
    "                if not keep_gt:\n",
    "                    train_dict[img_id].pop(min_idx)\n",
    "                result_flg.append(1)\n",
    "            else:\n",
    "                result_flg.append(0)\n",
    "            scores.append(pcar['carid_or_score'])\n",
    "    \n",
    "    return result_flg, scores    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_workers = 10\n",
    "def calculate_mAp(val_file_name):\n",
    "    valid_df = pd.read_csv(val_file_name)\n",
    "    expanded_valid_df = expand_df(valid_df, ['pitch','yaw','roll','x','y','z','Score'])\n",
    "    valid_df = valid_df.fillna('')\n",
    "    train_df = pd.read_csv('./dataset/train_remove.csv')    \n",
    "    train_df = train_df[train_df.ImageId.isin(valid_df.ImageId.unique())]\n",
    "    expanded_train_df = expand_df(train_df, ['model_type','pitch','yaw','roll','x','y','z'])\n",
    "\n",
    "    n_gt = len(expanded_train_df)\n",
    "    ap_list = []\n",
    "    p = Pool(processes=max_workers)\n",
    "    \n",
    "    input_data = []\n",
    "    for i in range(10):\n",
    "        input_data.append((i,train_df,valid_df))\n",
    "    \n",
    "    for result_flg, scores in p.starmap(check_match,input_data):\n",
    "#     for result_flg, scores in p.imap(check_match, input_data):\n",
    "        if np.sum(result_flg) > 0:\n",
    "            n_tp = np.sum(result_flg)\n",
    "            recall = n_tp/n_gt\n",
    "            scores = np.random.rand(len(result_flg))\n",
    "            ap = average_precision_score(result_flg, scores)*recall\n",
    "    #         print_pr_curve(result_flg, scores, recall)\n",
    "        else:\n",
    "            ap = 0\n",
    "        ap_list.append(ap)\n",
    "    mAp = np.mean(ap_list)\n",
    "    return mAp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_df = pd.read_csv(\"./best_model_kgroup/val_k20_model5_rmsprop_5e-4_b2_effb5_1536x320_flip0.5_bgTrue_peakScalar1_Clip1e-12_multiloss_Ep55_loss2.8832.csv\")\n",
    "# expanded_valid_df = expand_df(valid_df, ['pitch','yaw','roll','x','y','z','Score'])\n",
    "# valid_df = valid_df.fillna('')\n",
    "# train_df = pd.read_csv('./dataset/train_remove.csv')\n",
    "# train_df = train_df[train_df.ImageId.isin(valid_df.ImageId.unique())]\n",
    "# expanded_train_df = expand_df(train_df, ['model_type','pitch','yaw','roll','x','y','z'])\n",
    "# max_workers = 10\n",
    "# n_gt = len(expanded_train_df)\n",
    "# ap_list = []\n",
    "# p = Pool(processes=10)\n",
    "# input_data = []\n",
    "\n",
    "# for i in range(10):\n",
    "#     input_data.append((i,train_df,valid_df))\n",
    "    \n",
    "# for result_flg, scores in p.starmap(check_match,input_data):\n",
    "# # for result_flg, scores in p.imap(check_match, range(10)):\n",
    "#     if np.sum(result_flg) > 0:\n",
    "#         n_tp = np.sum(result_flg)\n",
    "#         recall = n_tp/n_gt\n",
    "        \n",
    "#         ###Get into it later\n",
    "#         score = np.random.rand(len(result_flg))\n",
    "#         ap = average_precision_score(result_flg, scores)*recall\n",
    "#         print_pr_curve(result_flg, scores, recall)\n",
    "#     else:\n",
    "#         ap = 0\n",
    "#     ap_list.append(ap)\n",
    "# map = np.mean(ap_list)\n",
    "# print('map:', map)\n",
    "\n",
    "# val_root = './best_model_pred_0116/No_optimizeXYZ'\n",
    "# val_root = './best_model_pred_0116/optimizer_para0.1_0.2'\n",
    "# val_root = './best_model_pred_0116/current_model_distances'\n",
    "val_root = './best_model_pred_0116/tmp'\n",
    "\n",
    "for file_name in os.listdir(val_root):\n",
    "    if file_name.find('val')!=-1:\n",
    "        continue\n",
    "    mAp = calculate_mAp(\"{}/{}\".format(val_root,file_name))\n",
    "    print(\"File:{}, mAp:{}\".format(file_name,mAp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/critic01_20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0,100):\n",
    "\n",
    "    i = idx\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = global_data.iloc[i, 0]\n",
    "    \n",
    "    if i%10==0:\n",
    "        plt.pause(.1)\n",
    "        fig, axes = plt.subplots(1,10,figsize=(16,2))\n",
    "    axes[i%10].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "    #     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "    #     img = transforms.functional.adjust_brightness(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_contrast(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_saturation(img, 5)\n",
    "#         axes[j][1].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "#     img = global_data_dig.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img = Image.fromarray(img)\n",
    "#     label = global_data_dig.iloc[i, 0]\n",
    "#     axes[2].imshow(img,cmap=\"gray\")\n",
    "#     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "#     axes[3].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "\n",
    "    print(\"Label:\",label)\n",
    "\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "###Confusion matrix\n",
    "print(classification_report(labels, result,digits=4))\n",
    "plt.figure(figsize=(10,10))\n",
    "confusion_mat = confusion_matrix(labels, result)\n",
    "sn.heatmap(confusion_mat, annot=True, cmap='YlGnBu',fmt=\"d\",linewidths=.5, linecolor='w')\n",
    "plt.title('Confusion matrix - DIG-MNIST dataset')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices1 = np.where(result!=labels)[0]       #(num)\n",
    "# indices2 = np.where(result_dig!=labels)[0]\n",
    "# indices3 = np.where((result!=labels)&(result_dig==labels))[0]\n",
    "indices4 = np.where((result[:,0]==labels))[0]\n",
    "indices5 = np.where((result[:,0]==labels)|(result[:,1]==labels))[0]\n",
    "indices6 = np.where((result[:,0]==labels)|(result[:,1]==labels)|(result[:,2]==labels))[0]\n",
    "\n",
    "cirtic_idx_list_ans0 = []\n",
    "idx_list_ans1 = []\n",
    "\n",
    "cirtic_idx_list_ans9 = []\n",
    "label_list = []\n",
    "count = 0\n",
    "\n",
    "data_num = len(labels)\n",
    "print(\"top1 acc:\",len(indices4)/data_num)\n",
    "print(\"top2 acc:\",len(indices5)/data_num)\n",
    "print(\"top3 acc:\",len(indices6)/data_num)\n",
    "stop\n",
    "\n",
    "for i in range(0,len(indices1)):\n",
    "    idx = indices1[i]\n",
    "#     img1 = global_dig.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img1 = global_pseudo_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = global_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = Image.fromarray(img1)\n",
    "    label1 = result[idx]\n",
    "#     label2 = result_dig[idx]\n",
    "    label2 = None\n",
    "    label = labels[idx]\n",
    "  \n",
    "\n",
    "#     if label == 0:\n",
    "#         fig, axes = plt.subplots(1,1,figsize=(2,2))\n",
    "# #         cirtic_idx_list_ans0.append(idx)\n",
    "#         axes.imshow(img1,cmap=\"gray\")\n",
    "#         print(idx)\n",
    "#         print(\"Model:\",label1,\" Model2:\",label2,\" Label:\",label)\n",
    "#         plt.pause(.1)\n",
    "#     else:\n",
    "#         continue\n",
    "        \n",
    "\n",
    "# print(idx_list_ans1)\n",
    "# np.save(\"idx_ans1\",idx_list_ans1)\n",
    "\n",
    "# print(cirtic_idx_list_ans0)\n",
    "# print(cirtic_idx_list_ans9)\n",
    "\n",
    "cirtic_idx_list_ans0_v2 = [5520,6150,12280,18560,32730]\n",
    "np.save(\"critic_idx_ans0_v2\",cirtic_idx_list_ans0_v2)\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(cirtic_label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "\n",
    "# 31 1 0 59969"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
